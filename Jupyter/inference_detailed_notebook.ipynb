{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c563c0fe",
   "metadata": {},
   "source": [
    "### Section 1: Import Required Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b024ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Milvus utilities for connections, schema creation, and managing collections.\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "\n",
    "# Import HuggingFace embeddings to convert text into vector representations.\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings  # Adjust if necessary.\n",
    "\n",
    "# Import parser to ensure the model outputs are formatted as strings.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Import PromptTemplate to structure and format prompts for the language model.\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Import RunnablePassthrough to allow passing data unchanged through multiple steps.\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Import Milvus to interact with the vector database for storage and retrieval.\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "# Import hybrid search retriever from Milvus, combining dense and sparse search techniques.\n",
    "from langchain_milvus.retrievers import MilvusCollectionHybridSearchRetriever\n",
    "\n",
    "# Import BM25 for sparse embedding, typically used for keyword-based search.\n",
    "from langchain_milvus.utils.sparse import BM25SparseEmbedding\n",
    "\n",
    "# Import ChatMistralAI to enable conversational interaction with the Mistral AI model.\n",
    "from langchain_mistralai.chat_models import ChatMistralAI\n",
    "\n",
    "# Import BeautifulSoup to parse and extract text content from HTML web pages.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import requests to make HTTP requests for web scraping or API calls.\n",
    "import requests\n",
    "\n",
    "# Import nltk (Natural Language Toolkit) for tokenizing text into sentences.\n",
    "import nltk\n",
    "\n",
    "# Import os for interacting with the operating system, such as handling environment variables.\n",
    "import os\n",
    "\n",
    "# Import urljoin to join relative and absolute URLs for web scraping.\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "# Import load_dotenv to load environment variables from a .env file into the program.\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a005f7a6",
   "metadata": {},
   "source": [
    "### Section 2: Load Environment Variables and Setup NLTK\n",
    "* Load environment variables from a .env file to access configuration\n",
    "* Download the 'punkt' tokenizer, which allows nltk to split text into sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables and setup nltk\n",
    "load_dotenv()\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfa3d4",
   "metadata": {},
   "source": [
    "### Section 3: Configure Mistral API Key\n",
    "* Retrieve the Mistral API key from the environment variables using os.getenv().\n",
    "* Set the Mistral API key as an environment variable so it can be accessed throughout the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b95c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve and set the Mistral API key\n",
    "mistral_api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "os.environ[\"MISTRAL_API_KEY\"] = mistral_api_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027289b",
   "metadata": {},
   "source": [
    "### Section 4: Connect to Milvus and Setup Collection Schema\n",
    "\n",
    "* stablish a connection to Milvus, using localhost as the host and default port 19530\n",
    "* Check if the collection \"my_collection\" already exists in Milvus.\n",
    "* Define fields for the Milvus collection schema. The ID field acts as the primary key.\n",
    "* Create a collection schema using the defined fields.\n",
    "* Initialize the collection with the name \"my_collection\" and the created schema.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to Milvus and set up the collection schema\n",
    "connections.connect(alias=\"default\", host=\"localhost\", port=\"19530\")\n",
    "if utility.has_collection(\"my_collection\"):\n",
    "    utility.drop_collection(\"my_collection\")\n",
    "\n",
    "fields = [\n",
    "    FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True),\n",
    "    FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=768)\n",
    "]\n",
    "schema = CollectionSchema(fields, description=\"My Collection for Embeddings\")\n",
    "collection = Collection(name=\"my_collection\", schema=schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f91bcd",
   "metadata": {},
   "source": [
    "### Section 5: Generate Embeddings and Insert Data into Milvus\n",
    "* Iinitialize the HuggingFace embeddings model to generate vector representations from text and set it to embeddings.\n",
    "\n",
    "* Define some sample data to insert into the Milvus collection and makes a list of IDs for the data points set to ids.\n",
    "\n",
    "* Generate embeddings for three sample sentences and gives it to Vectors\n",
    "* Insert the IDs and corresponding vector embeddings into the Milvus collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee7d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate embeddings and insert data into Milvus\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "ids = [1, 2, 3]\n",
    "vectors = embeddings.embed_documents([\"Hello world\", \"How are you?\", \"Goodbye\"])\n",
    "collection.insert([ids, vectors])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5754e555",
   "metadata": {},
   "source": [
    "### Section 6: Load the Mistral Chat Model\n",
    "* Load the ChatMistralAI model using the Mistral API key for authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168dd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load ChatMistralAI model\n",
    "chat_model = ChatMistralAI(api_key=mistral_api_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19410aad",
   "metadata": {},
   "source": [
    "### Section 7: Configure the Milvus Hybrid Search Retriever\n",
    "* Set up a hybrid search retriever using the Milvus collection and various embeddings.\n",
    "* `collection=collection`   Specify the Milvus collection to search.\n",
    "* `dense_embedding=embeddings`  Use HuggingFace dense embeddings for semantic search.\n",
    "* `sparse_embedding=BM25SparseEmbedding()`,  Use BM25 for  sparse, keyword-based search.\n",
    "* `top_k=2`  Return the top 2 most relevant documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715a4d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure Milvus hybrid search retriever\n",
    "retriever = MilvusCollectionHybridSearchRetriever(\n",
    "    collection=collection,\n",
    "    dense_embedding=embeddings,\n",
    "    sparse_embedding=BM25SparseEmbedding(),\n",
    "    top_k=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4199bcb",
   "metadata": {},
   "source": [
    "### Section 8: Create a Prompt Template and Output Parser\n",
    "\n",
    "* Define a prompt template to structure user queries for the language model\n",
    "* `input_variables=[\"question\"]` Specify the expected input variable.\n",
    "* `template=\"Answer the following question: {question}\" ` Format of the prompt.\n",
    "* Create an output parser to ensure the model response is converted to a string. `output_parser = StrOutputParser()`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up prompt template and output parser\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"Answer the following question: {question}\"\n",
    ")\n",
    "output_parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3dfa851",
   "metadata": {},
   "source": [
    "### Section 9: Set Up a RunnablePassthrough\n",
    "* Create a passthrough to pass data unchanged through different steps of the workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7c37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create passthrough for data routing in the workflow\n",
    "passthrough = RunnablePassthrough()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7479c994",
   "metadata": {},
   "source": [
    "### Section 10: Define a Web Scraping Function\n",
    "* Define a function to scrape text from a given website URL.\n",
    "\n",
    "* Send an HTTP GET request to the specified URL.\n",
    "* Parse the HTML content using BeautifulSoup\n",
    "* Extract and join all visible text from the HTML.\n",
    "*  Tokenize the extracted text into individual sentences using nltk.\n",
    "* Return the list of sentences extracted from the webpage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ceb1819",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to scrape a website\n",
    "def scrape_website(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    text = ' '.join(soup.stripped_strings)\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605723d9",
   "metadata": {},
   "source": [
    "### Section 11: Scrape a Website and Insert Data into Milvus\n",
    "\n",
    "* Define a website URL for scraping (example URL).\n",
    "* Scrape the website to get a list of sentences\n",
    "* Generate embeddings for the scraped sentences\n",
    "* Insert the sentences and their embeddings into the Milvus collection with autogenerated IDs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f57919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example URL to scrape\n",
    "website_url = \"https://example.com\"\n",
    "sentences = scrape_website(website_url)\n",
    "sentence_embeddings = embeddings.embed_documents(sentences)\n",
    "collection.insert([list(range(len(sentences))), sentence_embeddings])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66819b",
   "metadata": {},
   "source": [
    "### Section 12: Perform a Hybrid Search and Display Results\n",
    "* Define a user query to search the collection\n",
    "* Use the retriever to get the most relevant documents based on the query\n",
    "* Iterate through the retrieved results and print their content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6041d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Perform a hybrid search query and display results\n",
    "query = \"What is this website about?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "for result in results:\n",
    "    print(result.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
